{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e9beea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib \n",
    "from rdkit import Chem\n",
    "import math\n",
    "import itertools\n",
    "from rdkit import RDLogger\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "RDLogger.DisableLog('rdApp.*') # ignore the rdkit warnings\n",
    "\n",
    "def statistic_data(raw_data, verbose=True):\n",
    "    records = dict()\n",
    "    total_rxn = 0; total_context = 0\n",
    "    for reaction_name, data in raw_data.items():\n",
    "        t_rxn = len(set(data['Reaction ID']))\n",
    "        t_context = len(data)\n",
    "        records.update({reaction_name: [t_rxn, t_context]})\n",
    "        total_rxn += t_rxn\n",
    "        total_context += t_context\n",
    "        if verbose:\n",
    "            print(reaction_name, t_rxn, t_context)\n",
    "    if verbose:\n",
    "        print(\"Total reactions:\", total_rxn)\n",
    "        print(\"Total contexts:\", total_context)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cedc28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]C:\\Users\\lungyi\\anaconda3\\envs\\chemprop\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:09<00:00,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original reaction statistics: ---\n",
      "Buchwald-HartwigCross-Coupling 26767 43862\n",
      "Chan_LamCoupling 7170 10822\n",
      "DielsAlder 19565 26590\n",
      "FischerIndoleSynthesis 6869 8633\n",
      "Friedel-CraftsAcylation 10476 25844\n",
      "Friedel-CraftsAlkylation 17799 31396\n",
      "GrignardReaction 14019 23628\n",
      "KumadaCoupling 16808 21892\n",
      "NegishiCoupling 11514 13521\n",
      "ReductiveAmination 50668 58480\n",
      "Total reactions: 181655\n",
      "Total contexts: 264668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the number of each reaction set\n",
    "output_file_path = \"../data/reaxys_output\"\n",
    "reaxys_dir = \"../data/reaxys_input\"\n",
    "dir_names = ['Buchwald-HartwigCross-Coupling','Chan_LamCoupling','DielsAlder',\n",
    "             'FischerIndoleSynthesis','Friedel-CraftsAcylation','Friedel-CraftsAlkylation',\n",
    "             'GrignardReaction', 'KumadaCoupling', 'NegishiCoupling', 'ReductiveAmination'] # Change Here\n",
    "os.makedirs(output_file_path, exist_ok=True)\n",
    "\n",
    "def basic_preprocess(data_path):\n",
    "    keep_index = ['Reaction ID', 'Reaction', 'Temperature (Reaction Details) [C]', \n",
    "                  'Yield (numerical)','Reagent', 'Solvent (Reaction Details)', 'Catalyst']\n",
    "    data = pd.read_excel(data_path, engine=\"openpyxl\")\n",
    "    drop_index = list(data.columns)\n",
    "    for index in list(data.columns):\n",
    "        if index in keep_index:\n",
    "            drop_index.remove(index)\n",
    "    data = data.drop(drop_index,axis=1)\n",
    "    data = data[:-3] # copyright or something \n",
    "    return data\n",
    "\n",
    "# def reaction_entry(reaction_ids):\n",
    "#     now = '0'\n",
    "#     number = 0\n",
    "#     for id_ in reaction_ids:\n",
    "#         if id_ != now:\n",
    "#             number += 1\n",
    "#             now = id_\n",
    "#     return number\n",
    "            \n",
    "records = dict()\n",
    "raw_datas = dict()\n",
    "    \n",
    "file_path = os.path.join(reaxys_dir, dir_names[0])\n",
    "a = os.listdir(file_path)\n",
    "for dir_name in tqdm(dir_names):\n",
    "    file_path = os.path.join(reaxys_dir, dir_name)\n",
    "    for i, file_name in enumerate(os.listdir(file_path)):\n",
    "        data_path = os.path.join(file_path, file_name)\n",
    "        if i == 0:\n",
    "            reaction_set = basic_preprocess(data_path)\n",
    "        else:\n",
    "            data = basic_preprocess(data_path)\n",
    "            reaction_set = reaction_set.append(data, ignore_index=True)\n",
    "    \n",
    "#     records.update({dir_name: [reaction_entry(reaction_set['Reaction ID']), len(reaction_set['Reaction ID'])]})\n",
    "    raw_datas.update({dir_name : reaction_set})\n",
    "\n",
    "print(\"--- Original reaction statistics: ---\")\n",
    "records = statistic_data(raw_datas, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882e6583",
   "metadata": {},
   "source": [
    "# Remove the same reactions within different reaction types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d70b0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original reaction statistics: ---\n",
      "Buchwald-HartwigCross-Coupling 26767 43862\n",
      "Chan_LamCoupling 7170 10822\n",
      "DielsAlder 19564 26589\n",
      "FischerIndoleSynthesis 6869 8633\n",
      "Friedel-CraftsAcylation 10475 25840\n",
      "Friedel-CraftsAlkylation 17669 29361\n",
      "GrignardReaction 14007 23379\n",
      "KumadaCoupling 16487 20854\n",
      "NegishiCoupling 11185 12900\n",
      "ReductiveAmination 50664 58476\n",
      "Total reactions: 180857\n",
      "Total contexts: 260716\n"
     ]
    }
   ],
   "source": [
    "previous_reaction_id = set()\n",
    "for reaction_name, data in raw_datas.items():\n",
    "    indexNames = data[data['Reaction ID'].isin(previous_reaction_id)].index\n",
    "    data.drop(indexNames, inplace=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "    raw_datas.update({reaction_name: data})\n",
    "    previous_reaction_id.update(data['Reaction ID'])\n",
    "    \n",
    "print(\"--- Original reaction statistics: ---\")\n",
    "records = statistic_data(raw_datas, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28184fa",
   "metadata": {},
   "source": [
    "# Remove nan entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16d7afa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:08<00:00, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- After removing nan entries reaction statistics: ---\n",
      "Buchwald-HartwigCross-Coupling 12788 23468\n",
      "Chan_LamCoupling 4960 7143\n",
      "DielsAlder 8900 10794\n",
      "FischerIndoleSynthesis 1504 1808\n",
      "Friedel-CraftsAcylation 5112 8597\n",
      "Friedel-CraftsAlkylation 9617 15214\n",
      "GrignardReaction 7852 11590\n",
      "KumadaCoupling 8639 10598\n",
      "NegishiCoupling 7802 8784\n",
      "ReductiveAmination 15835 18066\n",
      "Total reactions: 83009\n",
      "Total contexts: 116062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def string_average(l_):\n",
    "    l_ = [float(x) for x in l_]\n",
    "    return np.average(l_)\n",
    "\n",
    "def highest_temperature(temp:str):\n",
    "    if str(temp) == 'nan':\n",
    "        return temp\n",
    "    temp = str(temp)\n",
    "    temps = temp.split('; ')\n",
    "    temps = [string_average(x.split(' - ')) for x in temps]\n",
    "    # temp = temp.split(' - ')\n",
    "    temp = max(temps)\n",
    "    return temp\n",
    "\n",
    "def remove_invalid_smiles(data):\n",
    "    rxn_id = list(data['Reaction ID'])\n",
    "    start_ = 0\n",
    "    result = []\n",
    "    for i in range(len(rxn_id)):\n",
    "        if rxn_id[i] != rxn_id[start_]:\n",
    "            end_ = i\n",
    "            result.append((start_, end_))\n",
    "            start_ = end_\n",
    "    rm_pair = []\n",
    "    for a, b in result:\n",
    "        if (Chem.MolFromSmiles(str(data['products'][a])) == None) or (Chem.MolFromSmiles(str(data['reactants'][a])) == None):\n",
    "            rm_pair.append((a,b))\n",
    "    if rm_pair:        \n",
    "        rm_pair = list(itertools.chain.from_iterable([list(range(a,b)) for a,b in rm_pair]))\n",
    "        data.drop(rm_pair, inplace=True)\n",
    "        data = data.reset_index(drop=True)\n",
    "    \n",
    "def CheckNaN(target):\n",
    "    try:\n",
    "        target = float(target)\n",
    "    except:\n",
    "        if target:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    return math.isnan(target)\n",
    "\n",
    "def CheckYield(target):\n",
    "    '''function for having yield report'''\n",
    "    try:\n",
    "        target = float(target)\n",
    "    except:\n",
    "        return True\n",
    "    return math.isnan(target)\n",
    "\n",
    "def remove_duplicated_records(records):\n",
    "    return '; '.join(list(dict.fromkeys(records.split('; '))))\n",
    "\n",
    "for reaction, data in tqdm(raw_datas.items()):\n",
    "    # split reaction smiles to reactant and product and remove no smiles data\n",
    "    data[['reactants', 'products']] = data['Reaction'].str.split('>>',expand=True)\n",
    "    data = data.drop(['Reaction'], axis=1)\n",
    "    # reactant\n",
    "    indexNames = data[ [CheckNaN(data.iloc[i]['reactants']) for i in range(len(data))] ].index\n",
    "    data.drop(indexNames, inplace=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "    # product\n",
    "    indexNames = data[ [CheckNaN(data.iloc[i]['products']) for i in range(len(data))] ].index\n",
    "    data.drop(indexNames, inplace=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "    # remove invalid SMILES\n",
    "    remove_invalid_smiles(data)\n",
    "    data = data.reset_index(drop=True)\n",
    "    # remove the data without solvent record\n",
    "    indexNames = data[ [CheckNaN(data.iloc[i]['Solvent (Reaction Details)']) for i in range(len(data))] ].index\n",
    "    data.drop(indexNames, inplace=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "    # remove the data without yield record\n",
    "    indexNames = data[ [CheckYield(data.iloc[i]['Yield (numerical)']) for i in range(len(data))] ].index\n",
    "    data.drop(indexNames, inplace=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "    # temperature: pick the highest temperature in the stages,\n",
    "    # (Because we train the ranking and regression using two separate dataset)\n",
    "    data['Temperature (Reaction Details) [C]'] = [highest_temperature(t) for t in data['Temperature (Reaction Details) [C]']]\n",
    "    \n",
    "    # remove the duplicate solvent or reagent in the same context entry\n",
    "    for i in range(len(data)):\n",
    "        data.loc[i,'Solvent (Reaction Details)'] = remove_duplicated_records(str(data.loc[i,'Solvent (Reaction Details)']))\n",
    "        data.loc[i,'Reagent'] = remove_duplicated_records(str(data.loc[i,'Reagent']))\n",
    "    \n",
    "    raw_datas.update({reaction: data})\n",
    "    \n",
    "print(\"\\n--- After removing nan entries reaction statistics: ---\")\n",
    "records = statistic_data(raw_datas, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9444dc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 228.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buchwald-HartwigCross-Coupling\n",
      "Counter({3: 13320, 2: 5509, 1: 3543, 4: 887, 5: 178, 6: 24, 7: 7})\n",
      "Chan_LamCoupling\n",
      "Counter({2: 3362, 3: 1972, 1: 1346, 4: 395, 5: 63, 6: 4, 7: 1})\n",
      "DielsAlder\n",
      "Counter({1: 8973, 2: 1348, 3: 347, 4: 120, 5: 6})\n",
      "FischerIndoleSynthesis\n",
      "Counter({1: 1498, 2: 244, 3: 47, 4: 19})\n",
      "Friedel-CraftsAcylation\n",
      "Counter({1: 7352, 2: 957, 3: 247, 4: 40, 7: 1})\n",
      "Friedel-CraftsAlkylation\n",
      "Counter({1: 11904, 2: 2801, 3: 409, 5: 35, 4: 34, 6: 30, 7: 1})\n",
      "GrignardReaction\n",
      "Counter({1: 7945, 2: 2419, 3: 971, 4: 206, 5: 45, 6: 4})\n",
      "KumadaCoupling\n",
      "Counter({1: 6448, 2: 3017, 3: 811, 4: 212, 5: 108, 6: 2})\n",
      "NegishiCoupling\n",
      "Counter({2: 2956, 1: 2657, 3: 1703, 4: 1062, 5: 347, 6: 50, 7: 8, 8: 1})\n",
      "ReductiveAmination\n",
      "Counter({2: 8407, 1: 7022, 3: 2225, 4: 365, 5: 46, 6: 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def count(x):\n",
    "    return len(x.split('; '))\n",
    "for reaction, data in tqdm(raw_datas.items()):\n",
    "    print(reaction)\n",
    "    emt = []\n",
    "    for e in data['Reagent']:\n",
    "        if type(e) != str:\n",
    "            continue\n",
    "        emt.append(count(e))\n",
    "    print(Counter(emt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7f7cf1",
   "metadata": {},
   "source": [
    "# Move some solvent name to reagent dictionary, and move some reagent name to solvent dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "560a49f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate reaction roles in both reagent and solvent: 93\n",
      "{'quinoline', 'ethylene dibromide', 'hydrogen fluoride', 'ethyl acetate', 'N,N-dimethyl-formamide', 'benzonitrile', '1,2-dichloro-ethane', 'sulfolane', 'N,N,N,N,N,N-hexamethylphosphoric triamide', 'nitromethane', 'cyclohexanone', 'triethylamine', 'alpha,alpha,alpha-trifluorotoluene', 'dimethyl sulfoxide', '1,4-dioxane', 'diethylene glycol dimethyl ether', \"1,1,1,3',3',3'-hexafluoro-propanol\", '1,3-dimethyl-2-imidazolidinone', 'nitrogen', 'cyclohexane', 'benzophenone', 'acetic acid', 'methoxybenzene', 'carbon dioxide', 'pentane', 'trichlorophosphate', '1,2-dimethoxyethane', 'methanol', 'ethylenediamine', 'acetic anhydride', 'octane', 'cyclohexenone', 'chlorobenzene', '1,1-Dibromoethane', 'carbon disulfide', 'trimethyl orthoformate', 'hydrogenchloride', 'ISOPROPYLAMIDE', 'pyridine', 'phosphate buffer', 'ethylene glycol', 'tetramethylurea', 'chloroform', 'pentan-3-one', 'trifluoroacetic anhydride', '1,2-dichloro-benzene', 'sulfuric acid', 'o-xylene', '2,2,2-trifluoroethanol', 'phenol', 'tert-butyl methyl ether', 'tert-Amyl alcohol', 'tetradecyl(trihexyl)phosphonium decanoate', 'polyphosphate ester', '1-Methylpyrrolidine', 'N,N-dimethyl acetamide', 'chlorosulfonic acid', 'methanesulfonic acid', '1-methyl-pyrrolidin-2-one', 'propan-1-ol', 'propionic acid', 'water', 'formic acid', 'decane', 'diethylamine', 'tert-butyl alcohol', 'formamide', 'nitrobenzene', 'para-xylene', 'bromobenzene', 'thionyl chloride', 'butan-1-ol', 'acetate buffer', 'N,N-dimethyl-aniline', 'isopropyl alcohol', 'trifluorormethanesulfonic acid', 'dimethyl amine', 'deuteromethanol', '2,4-dichlorophenoxyacetic acid dimethylamine', 'diethyl ether', 'phosphoric acid', 'glycerol', 'water-d2', 'sodium tris(acetoxy)borohydride', 'di-isopropyl ether', 'dodecane', '1-ethyl-2-pyrrolidinone', '1,3-dimethyl-3,4,5,6-tetrahydro-2(1H)-pyrimidinone', '1,2-dibromomethane', 'methylamine', 'ethanol', 'trifluoroacetic acid', 'tetrahydrofuran'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:14<00:00,  7.41s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:12<00:00,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- After updating reaction roles reaction statistics: ---\n",
      "Buchwald-HartwigCross-Coupling 12788 23445\n",
      "Chan_LamCoupling 4956 7133\n",
      "DielsAlder 8846 10731\n",
      "FischerIndoleSynthesis 1287 1554\n",
      "Friedel-CraftsAcylation 5088 8552\n",
      "Friedel-CraftsAlkylation 9570 15114\n",
      "GrignardReaction 7852 11585\n",
      "KumadaCoupling 8638 10597\n",
      "NegishiCoupling 7802 8781\n",
      "ReductiveAmination 15795 18024\n",
      "Total reactions: 82622\n",
      "Total contexts: 115516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def GetFrequencyDict(datas):\n",
    "    Dict = dict({'nan':0})\n",
    "    for data in datas:\n",
    "        if CheckNaN(data):\n",
    "            Dict['nan'] += 1\n",
    "            continue\n",
    "#         data = RemoveDuplicate(data)\n",
    "        for sub_data in data.split('; '):\n",
    "            if sub_data in Dict.keys():\n",
    "                Dict[sub_data] += 1\n",
    "            else:\n",
    "                Dict.update({sub_data:1})\n",
    "    return Dict\n",
    "\n",
    "all_data = pd.concat(raw_datas.values())\n",
    "reagent_dict = GetFrequencyDict(all_data['Reagent'])\n",
    "solvent_dict = GetFrequencyDict(all_data['Solvent (Reaction Details)'])\n",
    "solvent_dict.pop('nan',None)\n",
    "\n",
    "overlap = reagent_dict.keys() & solvent_dict.keys()\n",
    "print(\"Number of duplicate reaction roles in both reagent and solvent:\", len(overlap))\n",
    "print(overlap)\n",
    "\n",
    "# determine which the class it should be\n",
    "for key, value in solvent_dict.copy().items():\n",
    "    if reagent_dict.get(key):\n",
    "        if value >= reagent_dict[key]:\n",
    "            reagent_dict.pop(key, None)\n",
    "        else:\n",
    "            solvent_dict.pop(key, None)\n",
    "\n",
    "for reaction, data in tqdm(raw_datas.items()):\n",
    "    for i in range(len(data)):\n",
    "        r_s = data.loc[i,'Reagent'].split('; ')\n",
    "        s_s = data.loc[i,'Solvent (Reaction Details)'].split('; ')\n",
    "        for r in r_s.copy():\n",
    "            if r in solvent_dict.keys():\n",
    "                r_s.remove(r)\n",
    "                s_s.append(r)\n",
    "        for s in s_s.copy():\n",
    "            if s not in solvent_dict.keys():\n",
    "                s_s.remove(s)\n",
    "                r_s.append(s)\n",
    "        if r_s == []:\n",
    "            data.loc[i,'Reagent'] = 'nan'\n",
    "        else:\n",
    "            data.loc[i,'Reagent'] = '; '.join(r_s)\n",
    "        if s_s == []:\n",
    "            data.loc[i,'Solvent (Reaction Details)'] = 'nan'\n",
    "        else:\n",
    "            data.loc[i,'Solvent (Reaction Details)'] = '; '.join(s_s)\n",
    "\n",
    "\n",
    "    indexNames = data[ [CheckNaN(data.iloc[i]['Solvent (Reaction Details)']) for i in range(len(data))] ].index\n",
    "    data.drop(indexNames, inplace=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "    raw_datas.update({reaction:data})\n",
    "    \n",
    "for reaction, data in tqdm(raw_datas.items()):\n",
    "    for i in range(len(data)):    \n",
    "        data.loc[i,'Solvent (Reaction Details)'] = remove_duplicated_records(str(data.loc[i,'Solvent (Reaction Details)']))\n",
    "        data.loc[i,'Reagent'] = remove_duplicated_records(str(data.loc[i,'Reagent']))\n",
    "    raw_datas.update({reaction:data})\n",
    "    \n",
    "print(\"\\n--- After updating reaction roles reaction statistics: ---\")\n",
    "records = statistic_data(raw_datas, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107a0e4c",
   "metadata": {},
   "source": [
    "# Remove the reaction with solvent >= 3 or reagent number >= 4, data information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a2fa6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'remove_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8304\\586877371.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mraw_datas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mreaction\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The percent of data being removed: {:.2f}%\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremove_data\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mall_number_data\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n--- After removing solvent >= 3 or reagent >= 4 reaction statistics: ---\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mrecords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstatistic_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_datas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'remove_data' is not defined"
     ]
    }
   ],
   "source": [
    "def CheckSemicolon_count(target, count = 3):\n",
    "    if (type(target) == float) and math.isnan(target):\n",
    "        return False\n",
    "    return target.count('; ')+1 >= count\n",
    "\n",
    "all_number_data = 0\n",
    "remove_number_data = 0\n",
    "for reaction, data in raw_datas.items():\n",
    "    all_number_data += len(data)\n",
    "    indexNames = data[ [CheckSemicolon_count(str(data.iloc[i]['Solvent (Reaction Details)'])) for i in range(len(data))] ].index\n",
    "    data.drop(indexNames, inplace=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "    remove_number_data += len(indexNames)\n",
    "    \n",
    "    indexNames = data[ [CheckSemicolon_count(str(data.iloc[i]['Reagent']), count = 4) for i in range(len(data))] ].index\n",
    "    data.drop(indexNames, inplace=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "    remove_number_data += len(indexNames)\n",
    "\n",
    "    raw_datas.update({reaction:data})\n",
    "\n",
    "print(\"The percent of data being removed: {:.2f}%\\n\".format(remove_number_data / all_number_data * 100))\n",
    "print(\"\\n--- After removing solvent >= 3 or reagent >= 4 reaction statistics: ---\")\n",
    "records = statistic_data(raw_datas, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7720dfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percent of data being removed: 5.33%\n",
      "\n",
      "\n",
      "--- After removing solvent >= 3 or reagent >= 4 reaction statistics: ---\n",
      "Buchwald-HartwigCross-Coupling 12233 22353\n",
      "Chan_LamCoupling 4606 6637\n",
      "DielsAlder 8604 10449\n",
      "FischerIndoleSynthesis 1268 1528\n",
      "Friedel-CraftsAcylation 5056 8480\n",
      "Friedel-CraftsAlkylation 9472 14999\n",
      "GrignardReaction 7508 10962\n",
      "KumadaCoupling 8254 10057\n",
      "NegishiCoupling 6212 6918\n",
      "ReductiveAmination 14886 16975\n",
      "Total reactions: 78099\n",
      "Total contexts: 109358\n"
     ]
    }
   ],
   "source": [
    "print(\"The percent of data being removed: {:.2f}%\\n\".format(remove_number_data / all_number_data * 100))\n",
    "print(\"\\n--- After removing solvent >= 3 or reagent >= 4 reaction statistics: ---\")\n",
    "records = statistic_data(raw_datas, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2af88df",
   "metadata": {},
   "source": [
    "# Remove duplicated reaction condition records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cdc5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for reaction, data in raw_datas.items():\n",
    "    rxn_id = list(data['Reaction ID'])\n",
    "    start_ = 0\n",
    "    result = []\n",
    "    memory = []\n",
    "    indexNames = []\n",
    "    for i in range(len(rxn_id)):\n",
    "        if rxn_id[i] != rxn_id[start_]:\n",
    "            start_ = i\n",
    "            memory = [str(data.iloc[i]['Reagent'])+'+'+str(data.iloc[i]['Solvent (Reaction Details)'])]\n",
    "        else:\n",
    "            condition = str(data.iloc[i]['Reagent'])+'+'+str(data.iloc[i]['Solvent (Reaction Details)'])\n",
    "            if condition not in memory:\n",
    "                memory.append(condition)\n",
    "            else:\n",
    "                indexNames.append(i)\n",
    "\n",
    "    data.drop(indexNames, inplace=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "    raw_datas.update({reaction:data})\n",
    "    \n",
    "print(\"\\n--- After removing duplicate entries reaction statistics: ---\")\n",
    "records = statistic_data(raw_datas, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9a14c",
   "metadata": {},
   "source": [
    "# Observe the frequency dict of reagent & solvent, almost zero catalyst in Reaxys data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78996477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveDuplicate(target):\n",
    "    target = list(set(target.split('; ')))\n",
    "    return target\n",
    "\n",
    "def GetFrequencyDict(datas):\n",
    "    Dict = dict({'nan':0})\n",
    "    for data in datas:\n",
    "        if CheckNaN(data):\n",
    "            Dict['nan'] += 1\n",
    "            continue\n",
    "        data = RemoveDuplicate(data)\n",
    "        for sub_data in data:\n",
    "            if sub_data in Dict.keys():\n",
    "                Dict[sub_data] += 1\n",
    "            else:\n",
    "                Dict.update({sub_data:1})\n",
    "    return Dict\n",
    "\n",
    "def make_hist(ax, x, bins=None, binlabels=None, width=0.85, extra_x=1, extra_y=4, \n",
    "              text_offset=0.3, title=r\"Frequency diagram\", \n",
    "              xlabel=\"Values\", ylabel=\"Frequency\"):\n",
    "    if bins is None:\n",
    "        xmax = max(x)+extra_x\n",
    "        bins = range(xmax+1)\n",
    "    if binlabels is None:\n",
    "        if np.issubdtype(np.asarray(x).dtype, np.integer):\n",
    "            binlabels = [str(bins[i]) if bins[i+1]-bins[i] == 1 else \n",
    "                         '{}-{}'.format(bins[i], bins[i+1]-1)\n",
    "                         for i in range(len(bins)-1)]\n",
    "        else:\n",
    "            binlabels = [str(bins[i]) if bins[i+1]-bins[i] == 1 else \n",
    "                         '{}-{}'.format(*bins[i:i+2])\n",
    "                         for i in range(len(bins)-1)]\n",
    "        if bins[-1] == np.inf:\n",
    "            binlabels[-1] = '{}+'.format(bins[-2])\n",
    "    n, bins = np.histogram(x, bins=bins)\n",
    "    patches = ax.bar(range(len(n)), n, align='center', width=width)\n",
    "    ymax = max(n)+extra_y\n",
    "\n",
    "    ax.set_xticks(range(len(binlabels)))\n",
    "    ax.set_xticklabels(binlabels)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_ylim(0, ymax)\n",
    "    ax.grid(True, axis='y')\n",
    "    # http://stackoverflow.com/a/28720127/190597 (peeol)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    # http://stackoverflow.com/a/11417222/190597 (gcalmettes)\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    autolabel(patches, text_offset)\n",
    "\n",
    "def autolabel(rects, shift=0.3):\n",
    "    \"\"\"\n",
    "    http://matplotlib.org/1.2.1/examples/pylab_examples/barchart_demo.html\n",
    "    \"\"\"\n",
    "    # attach some text labels\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        if height > 0:\n",
    "            plt.text(rect.get_x()+rect.get_width()/2., height+shift, '%d'%int(height),\n",
    "                     ha='center', va='bottom')\n",
    "\n",
    "def plot_frequency(Dict:dict, title_name = 'Frequency Plot', save_path= None):\n",
    "    x = list(Dict.values())\n",
    "    fig, ax = plt.subplots(figsize=(14,5), dpi = 800)\n",
    "    # make_hist(ax, x)\n",
    "    # make_hist(ax, [1,1,1,0,0,0], extra_y=1, text_offset=0.1)\n",
    "    make_hist(ax, x, bins=list(range(0,10,2))+list(range(10,1010,200))+[np.inf], extra_y=6, title= title_name)\n",
    "    # plt.show()\n",
    "    if save_path is not None:\n",
    "        fig.savefig(save_path)\n",
    "\n",
    "all_data = pd.concat(raw_datas.values())\n",
    "reagent_dict = GetFrequencyDict(all_data['Reagent'])\n",
    "plot_frequency(reagent_dict, 'Reagent', os.path.join(output_file_path, 'Reagent_plot_first.png'))\n",
    "solvent_dict = GetFrequencyDict(all_data['Solvent (Reaction Details)'])\n",
    "solvent_dict.pop('nan', None)\n",
    "plot_frequency(solvent_dict, 'Solvent', os.path.join(output_file_path, 'Solvent_plot_first.png'))\n",
    "catalyst_dict = GetFrequencyDict(all_data['Catalyst'])\n",
    "plot_frequency(catalyst_dict, 'Catalyst')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab3634",
   "metadata": {},
   "source": [
    "# After observing the distribution of reagent and solvent data, now we remove data that uses reagent and solvent whose frequency < 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfff978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_remove_list(Dict:dict, freq:int):\n",
    "    rm = [key for key, value in Dict.items() if value < freq ]\n",
    "    return rm\n",
    "def check_rm(reag:str, rm:list):\n",
    "    if str(reag) == 'nan':\n",
    "        return False\n",
    "    reag = reag.split('; ')\n",
    "    for x in reag:\n",
    "        if x in rm:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "rm_reagent = get_remove_list(reagent_dict, 10)\n",
    "rm_solvent = get_remove_list(solvent_dict, 10)\n",
    "\n",
    "for reaction, data in raw_datas.items():\n",
    "    indexNames = data[ [check_rm(data.iloc[i]['Reagent'], rm_reagent) for i in range(len(data))] ].index\n",
    "    data.drop(indexNames, inplace=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "    indexNames = data[ [check_rm(data.iloc[i]['Solvent (Reaction Details)'], rm_solvent) for i in range(len(data))] ].index\n",
    "    data.drop(indexNames, inplace=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    raw_datas.update({reaction:data})\n",
    "'''\n",
    "second remove < 5\n",
    "'''\n",
    "all_data = pd.concat(raw_datas.values())\n",
    "reagent_dict = GetFrequencyDict(all_data['Reagent'])\n",
    "solvent_dict = GetFrequencyDict(all_data['Solvent (Reaction Details)'])\n",
    "solvent_dict.pop('nan', None)\n",
    "rm_reagent = get_remove_list(reagent_dict, 5)\n",
    "rm_solvent = get_remove_list(solvent_dict, 5)\n",
    "\n",
    "for reaction, data in raw_datas.items():\n",
    "    indexNames = data[ [check_rm(data.iloc[i]['Reagent'], rm_reagent) for i in range(len(data))] ].index\n",
    "    data.drop(indexNames, inplace=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "    indexNames = data[ [check_rm(data.iloc[i]['Solvent (Reaction Details)'], rm_solvent) for i in range(len(data))] ].index\n",
    "    data.drop(indexNames, inplace=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    raw_datas.update({reaction:data})\n",
    "\n",
    "print(\"\\n--- After removing the entries using rare (<10) condition labels reaction statistics: ---\")\n",
    "records = statistic_data(raw_datas, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8872eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat(raw_datas.values())\n",
    "reagent_dict = GetFrequencyDict(all_data['Reagent'])\n",
    "plot_frequency(reagent_dict, 'Reagent Frequency After Removal', os.path.join(output_file_path, 'Reagent_plot_second.png'))\n",
    "solvent_dict = GetFrequencyDict(all_data['Solvent (Reaction Details)'])\n",
    "solvent_dict.pop('nan', None)\n",
    "plot_frequency(solvent_dict, 'Solvent Frequency After Removal', os.path.join(output_file_path, 'Solvent_plot_second.png'))\n",
    "\n",
    "print('After removing data with frequency < 10: ')\n",
    "all_data.info()\n",
    "print('-'*50 + '\\n')\n",
    "all_data.to_csv(os.path.join(output_file_path, 'processed_data.csv'))\n",
    "print('Catalyst used ratio: {:.2f}%'.format(1465/93216*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eeca4b",
   "metadata": {},
   "source": [
    "# Final Part: split and save the data\n",
    "### (1) train, validate and test data (pd.Dataframe) -> .txt\n",
    "### (2) solvent and reagent name classes (dict) -> .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780497af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split_for_Reaxys_condition(data, train_percent=0.8, validate_percent=0.1, SEED=45):\n",
    "    '''We have to split the data according to its Reaxys ID. '''\n",
    "    rxn_id = list(data['Reaction ID'])\n",
    "    start_ = 0\n",
    "    result = []\n",
    "    for i in range(len(rxn_id)):\n",
    "        if rxn_id[i] != rxn_id[start_]:\n",
    "            end_ = i\n",
    "            result.append((start_, end_))\n",
    "            start_ = end_\n",
    "    result = shuffle(result, random_state=SEED)\n",
    "    train_index = int(len(result)*train_percent)\n",
    "    validate_index = int(len(result)*(train_percent + validate_percent))\n",
    "    train_list = result[0:train_index]\n",
    "    validate_list = result[train_index:validate_index]\n",
    "    test_list = result[validate_index:]\n",
    "    \n",
    "    train_list = list(itertools.chain.from_iterable([list(range(a,b)) for a,b in train_list]))\n",
    "    validate_list = list(itertools.chain.from_iterable([list(range(a,b)) for a,b in validate_list]))\n",
    "    test_list = list(itertools.chain.from_iterable([list(range(a,b)) for a,b in test_list]))\n",
    "    return train_list\n",
    "#     return data.loc[train_list], data.loc[validate_list], data.loc[test_list]\n",
    "A = train_validate_test_split_for_Reaxys_condition(all_data)\n",
    "all_data.iloc[A]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee16e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split_for_Reaxys_condition(data, train_percent=0.8, validate_percent=0.1, SEED=45):\n",
    "    '''We have to split the data according to its Reaxys ID. '''\n",
    "    rxn_id = list(data['Reaction ID'])\n",
    "    start_ = 0\n",
    "    result = []\n",
    "    for i in range(len(rxn_id)):\n",
    "        if rxn_id[i] != rxn_id[start_]:\n",
    "            end_ = i\n",
    "            result.append((start_, end_))\n",
    "            start_ = end_\n",
    "    result = shuffle(result, random_state=SEED)\n",
    "    train_index = int(len(result)*train_percent)\n",
    "    validate_index = int(len(result)*(train_percent + validate_percent))\n",
    "    train_list = result[0:train_index]\n",
    "    validate_list = result[train_index:validate_index]\n",
    "    test_list = result[validate_index:]\n",
    "    \n",
    "    train_list = list(itertools.chain.from_iterable([list(range(a,b)) for a,b in train_list]))\n",
    "    validate_list = list(itertools.chain.from_iterable([list(range(a,b)) for a,b in validate_list]))\n",
    "    test_list = list(itertools.chain.from_iterable([list(range(a,b)) for a,b in test_list]))\n",
    "    return data.iloc[train_list], data.iloc[validate_list], data.iloc[test_list]\n",
    "\n",
    "def write_DF2text_second_part(data, output_path):\n",
    "    f = open(output_path, 'w', encoding='UTF-8')\n",
    "    for i in range(len(data)):\n",
    "        row = data.iloc[i]\n",
    "        text = str(row['Reaction ID']+'\\t'+row['reactants'])+'\\t'+str(row['products'])+'\\t'+str(row['Yield (numerical)'])+'\\t' \\\n",
    "        +str(row['Reagent'])+'\\t'+str(row['Solvent (Reaction Details)'])+'\\t'+str(row['Temperature (Reaction Details) [C]'])+'\\n'\n",
    "        f.write(text)\n",
    "    f.close()\n",
    "\n",
    "def write_DF2text_first_part(data, output_path):\n",
    "    rxn_id = list(data['Reaction ID'])\n",
    "    start_ = 0\n",
    "    result = []\n",
    "    for i in range(len(rxn_id)):\n",
    "        if rxn_id[i] != rxn_id[start_]:\n",
    "            end_ = i\n",
    "            result.append((start_, end_))\n",
    "            start_ = end_\n",
    "    f = open(output_path, 'w', encoding='UTF-8')\n",
    "    for pair in result:\n",
    "        data_ = data.iloc[list(range(*pair))]\n",
    "        rxn_id = str(data_['Reaction ID'][pair[0]])\n",
    "        reactant = str(data_['reactants'][pair[0]])\n",
    "        product = str(data_['products'][pair[0]])\n",
    "        solvents = list(data_['Solvent (Reaction Details)'])\n",
    "        reagents = list(data_['Reagent'])\n",
    "        solvents = make_classes(solvents)\n",
    "        reagents = make_classes(reagents)\n",
    "        text = rxn_id+'\\t'+reactant+'\\t'+product+'\\t'+reagents+'\\t'+solvents+'\\n'\n",
    "        f.write(text)\n",
    "    f.close()\n",
    "\n",
    "def save_dict2pkl(Dict:dict, output_path):\n",
    "    f = open(output_path, 'wb')\n",
    "    pickle.dump(Dict, f)\n",
    "    f.close()\n",
    "\n",
    "def make_classes(k:list):\n",
    "    a = []\n",
    "    for conds in k:\n",
    "        conds = str(conds) # consider the float type nan\n",
    "        for cond in conds.split('; '):\n",
    "            if cond not in a:\n",
    "                a.append(cond)\n",
    "    return '; '.join(a)\n",
    "\n",
    "all_data = pd.concat(raw_datas.values()).reset_index(drop=True)\n",
    "train_data, validate_data, test_data = train_validate_test_split_for_Reaxys_condition(all_data)\n",
    "\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "validate_data = validate_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "output_file_path_second_part = os.path.join(output_file_path, 'For_second_part_model')\n",
    "os.makedirs(output_file_path_second_part, exist_ok=True)\n",
    "\n",
    "write_DF2text_second_part(all_data, os.path.join(output_file_path_second_part, 'Splitted_second_{}.txt'.format('total')))\n",
    "write_DF2text_second_part(train_data, os.path.join(output_file_path_second_part, 'Splitted_second_{}.txt'.format('train')))\n",
    "write_DF2text_second_part(validate_data, os.path.join(output_file_path_second_part, 'Splitted_second_{}.txt'.format('validate')))\n",
    "write_DF2text_second_part(test_data, os.path.join(output_file_path_second_part, 'Splitted_second_{}.txt'.format('test')))\n",
    "\n",
    "output_file_path_class = os.path.join(output_file_path, 'unprocessed_class')\n",
    "os.makedirs(output_file_path_class, exist_ok=True)\n",
    "save_dict2pkl(reagent_dict, os.path.join(output_file_path_class, 'class_names_{}.pkl'.format('reagent')))\n",
    "save_dict2pkl(solvent_dict, os.path.join(output_file_path_class, 'class_names_{}.pkl'.format('solvent')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d949f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path_first_part = os.path.join(output_file_path, 'For_first_part_model')\n",
    "os.makedirs(output_file_path_first_part, exist_ok=True)\n",
    "\n",
    "write_DF2text_first_part(all_data, os.path.join(output_file_path_first_part, 'Splitted_first_{}.txt'.format('total')))\n",
    "write_DF2text_first_part(train_data, os.path.join(output_file_path_first_part, 'Splitted_first_{}.txt'.format('train')))\n",
    "write_DF2text_first_part(validate_data, os.path.join(output_file_path_first_part, 'Splitted_first_{}.txt'.format('validate')))\n",
    "write_DF2text_first_part(test_data, os.path.join(output_file_path_first_part, 'Splitted_first_{}.txt'.format('test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e02f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Write the solvent and reagent dictionary into .txt files. => for label process\n",
    "\"\"\"\n",
    "\n",
    "f = open(os.path.join(output_file_path_class, 'class_names_reagent.txt'), 'w', encoding='UTF-8')\n",
    "for key, value in reagent_dict.items():\n",
    "    f.write(key + '\\n')\n",
    "f.close()\n",
    "f = open(os.path.join(output_file_path_class, 'class_names_solvent.txt'), 'w', encoding='UTF-8')\n",
    "for key, value in solvent_dict.items():\n",
    "    f.write(key + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9505c11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
